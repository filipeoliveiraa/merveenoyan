<img width="966" alt="Banner" src="https://github.com/merveenoyan/merveenoyan/assets/53175384/57bd2415-9b8b-49a9-8bba-87696a4c27fc">


<h1 align="center">Hi 👋, I'm Merve</h1>

I build, write, showcase around zero-shot vision, multimodality, optimization and more at Hugging Face (mostly transformers). Check out my pinned projects on GH.
My [Hugging Face profile](https://huggingface.co/merve) has a lot of cool stuff and I also write blogs over there. 

▶️ [A walkthrough on multimodality, papers, tools and more](https://www.youtube.com/watch?v=IoGaGfU1CIg)
▶️ [A video on open-source LLMs, where to find them, how to eval and deploy](https://www.youtube.com/watch?v=e9gNEAlsOvU)
▶️ [A walkthrough on zero-shot vision, papers, tools and more](https://www.youtube.com/watch?v=BnM-S50P_so)

🔖 [Fine-tuning Florence-2 - Microsoft's Cutting-edge Vision Language Models](https://huggingface.co/blog/finetune-florence2)
🔖 [Vision Language Models Explained](https://huggingface.co/blog/vlms)
🔖 [PaliGemma – Google's Cutting-Edge Open Vision Language Model](https://huggingface.co/blog/paligemma)
🔖 [Introduction to Quantization](https://huggingface.co/blog/merve/quantization)


## 🔗 Let's Connect!
<a href="https://twitter.com/mervenoyann" target="_blank"><img alt="Twitter" src="https://img.shields.io/badge/twitter-%231DA1F2.svg?&style=for-the-badge&logo=twitter&logoColor=white" /></a>
<a href="https://medium.com/@merveenoyan" target="_blank"><img alt="Medium" src="https://img.shields.io/badge/medium-%2312100E.svg?&style=for-the-badge&logo=medium&logoColor=white" /></a>
<a href="https://www.linkedin.com/in/merve-noyan-28b1a113a/" target="_blank"><img alt="LinkedIn" src="https://img.shields.io/badge/linkedin-%230077B5.svg?&style=for-the-badge&logo=linkedin&logoColor=white" /></a>
